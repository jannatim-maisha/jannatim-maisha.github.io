---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---
<b>Areas of Interests:</b>
Machine Learning, Natural Language Processing, Computer Vision, Large Language Model, Signal Processing.
  
## Publications
<script src="https://bibbase.org/show?bib=https%3A%2F%2Fbibbase.org%2Fnetwork%2Ffiles%2F8DrJ4qd2uE8fmm5JR&noBootstrap=1&jsonp=1"></script>

## Under Review

- F. H. Swarnali, **J. Maisha**, M. A. Mahtab, M. S. I. Iftikar, and F. M. Shah, “**Bengali multi-class text classification via enhanced contrastive learning techniques**,” in *2024 27th International Conference on Computer and Information Technology (ICCIT)*, Cox’s Bazar, Bangladesh.  
  <details> 
  <summary>Abstract</summary> 
  Bengali, one of South Asia's most frequently spoken languages, poses substantial challenges in tasks such as sentiment analysis and other forms of text classification due to its complex grammatical structure. Improving classification methods to address these subtle distinctions is crucial for advancing natural language processing in Bengali. Our study introduces Token-level Adversarial Contrastive Training (TACT) and Label-aware Contrastive Loss (LCL), leveraging contrastive learning methods to improve fine-grained text classification. For binary classification, TACT achieved an F1-score of 98%, setting a new benchmark on the Rokomari Book Review (RBR) dataset. For multi-class classification, TACT achieved an F1-score of 91%, matching the current benchmark on the Bengali Hate Speech (BHS-M) dataset. We also present the Daraz Product Review (DPR) dataset, further contributing to the field of Bengali text classification.
  </details>

- M. A. Mahtab, **J. Maisha**, M. M. Rahman, and S. K. S. Joy, “**An empirical study on utilizing large language models for Bengali image caption generation**,” in *2024 27th International Conference on Computer and Information Technology (ICCIT)*, Cox’s Bazar, Bangladesh.  
  <details> 
  <summary>Abstract</summary> 
  Generating effective image captions in Bengali requires not only describing what is happening in the image but also accurately identifying traditional objects by their local representative terms. To achieve this, we explored the potential of Large Language Models (LLMs) for Bengali image captioning. Using CLIP encodings as a prefix to the captions and fine-tuning BanglaGPT, we developed models that outperform existing benchmarks. On the BanglaLekha dataset, our best model achieved BLEU-4 and CIDEr scores of 54.3 and 95.9, respectively, while on the BNature dataset, it achieved 67.4 and 76.9. This study demonstrates significant advancements in Bengali image captioning.
  </details>

## Conference Presentation

- **A Study of Contrastive Learning Methods for Bengali Social Analysis**, *6th International Conference on Electrical Engineering and Information & Communication Technology (ICEEICT)*, Dhaka, Bangladesh. [Presentation link](https://www.youtube.com/watch?v=Czj9QxdQjM)

## Ongoing Projects

- Contrastive Learning methods in code-mixed languages.
- Sub-Dialect Detection and Translation.
- Plagiarism Detection in Bengali Cover Songs.



__________________________________________________